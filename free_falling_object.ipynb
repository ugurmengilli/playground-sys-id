{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# System Identification of a Freely Falling Ball\n",
    "\n",
    "The data in `data/falling_object.npy` provides the motion of a ball (only its position), freely falling (without friction) under the gravity of one of the solar system's planets. You are supposed to find which planet the ball is closest to. Perform this task in two different ways:\n",
    "\n",
    "1. Implement the adjoint differentiation method in Python/JAX and use the gradients provided by this method to figure out the gravitational constant.\n",
    "2. Use JAX 's built-in functions `jax.grad` or `jax.value_and_grad` to replace the adjoint differentiation method and repeat the task.\n",
    "3. Do both methods converge? Which method is faster? Can you make JAX 's grad (or value_and_grad) work faster?\n",
    "\n",
    "The data contains 1000 floats that correspond to the vertical motion of the ball. Each time step corresponds to 0.001 seconds of motion. The time interval between the initial and final time step is thus 1 second."
   ],
   "id": "f85595bd9de85c52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:43:07.658615Z",
     "start_time": "2025-03-19T20:43:07.548248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data import fallingobject\n",
    "\n",
    "# Load height trajectory of the object.\n",
    "ut, t_eval, dt = fallingobject.load_data()"
   ],
   "id": "44dac78cd0074d49",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Problem Definition\n",
    "\n",
    "The following second-order ODE represents the system behavior.\n",
    "$$\n",
    "    \\frac{d^2x}{dt^2} = \\ddot x = g,            \\tag{1}\n",
    "$$\n",
    "where $x$ is the height of the object and $g$ is the unknown gravitational acceleration.\n",
    "An analytical solution $x(t)$ of this simple ODE follows from double integration:\n",
    "$$\n",
    "    v(t) = \\int_{0}^{t} g d\\tau = v(0) + g t,   \\tag{2}\n",
    "$$$$\n",
    "    x(t) = \\int_{0}^{t} v(\\tau) d\\tau = x(0) + v(0) t + \\frac{1}{2} g t^2.  \\tag{3}\n",
    "$$\n",
    "Given the measurements, we know the initial position $x(0)$, but the initial velocity $v(0)$ and $g$ are unknown.\n",
    "Since Eq. (3) is linear in the unknown parameters, we can find the least-square estimate of $v(0)$ and $g$, but the solution will serve as **ground truth values** for the subsequent analyses."
   ],
   "id": "e041b8b0fc51b7a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:43:07.682355Z",
     "start_time": "2025-03-19T20:43:07.663630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# Coefficient matrix of the unknown vector (v0, g) and the RHS of eq.\n",
    "A = np.array([[t, 0.5*t*t] for t in t_eval])\n",
    "b = np.array(ut - ut[0]).reshape(-1)\n",
    "# Least squared estimate of the unknowns.\n",
    "x, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "g_best = x[1]\n",
    "v0_best = x[0]\n",
    "print(f\"LS estimate of grav. acc.: {g_best:.5f}\")\n",
    "print(f\"LS estimate of init. vel.: {v0_best:.5f}\")"
   ],
   "id": "3fdbe6fef7a1bd94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS estimate of grav. acc.: -3.70002\n",
      "LS estimate of init. vel.: 0.10185\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## System Model\n",
    "\n",
    "It is convenient to model this simple problem as a system of first-order ODEs to explore the methodology before applying it to more complex scenarios.\n",
    "$$\n",
    "    \\frac{d\\mathbf{u}}{dt}(t) = \\mathbf{f}(\\mathbf{u}(t), t; \\mathbf{p})    \\tag{4}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "        f_1(\\mathbf{u}(t), t; \\mathbf{p}) \\\\\n",
    "        f_2(\\mathbf{u}(t), t; \\mathbf{p})\n",
    "    \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix} u_2 \\\\ p_1 \\end{bmatrix},\\;\\;\\;\n",
    "    \\mathbf{u}(t_0) = \\begin{bmatrix} u_1(t_0) \\\\ p_2 \\end{bmatrix},\n",
    "$$\n",
    "where the variables $u_1 = x$, $u_2 = \\dot x = v$, and the parameter $p_1 = g$.\n",
    "This form of the problem also inherits the **unknown initial velocity** $p_2 = v(t_0)$ as the previous approach.\n",
    "Therefore, the following section considers optimizing these two parameters using the adjoint method.\n",
    "\n",
    "## Optimization of the Unknown Parameters\n",
    "\n",
    "We can find the optimal parametrization of the system model in Eq. (2), complying with the measurements $u_1(t)$ for some time range, by defining an objective (loss) function of the form:\n",
    "$$\n",
    "\\begin{align}\n",
    "    J(\\mathbf{u}(t); \\mathbf{p}) &=\n",
    "        \\int_{t_0}^{T} h(\\mathbf{u}(t); \\mathbf{p}) dt,                     \\tag{5} \\\\\n",
    "    h(\\mathbf{u}(t); \\mathbf{p}) &=\n",
    "        \\frac{1}{2} (u_1(t; \\mathbf{p}) - u_1^{*}(t))^2,                    \\tag{6}\n",
    "\\end{align}\n",
    "$$\n",
    "where $u_1^{*}$ are the true values.\n",
    "The parameters with the least average error along the measured trajectory are obtained by minimizing Eq. (5) over the parameter(s) $\\mathbf{p}$ subject to Eq. (4).\n",
    "However, the constraint optimization can be solved by minimizing the Lagrangian function.\n",
    "$$\n",
    "    \\mathcal{L}(\\mathbf{u}(t); \\mathbf{p}) =                                \\tag{7}\n",
    "    J(\\mathbf{u}(t); \\mathbf{p}) + \\int_{t_0}^{T} \\lambda(t)^\\top \\left(\n",
    "        \\mathbf{f}(\\mathbf{u}(t), t; \\mathbf{p}) - \\frac{d\\mathbf{u}}{dt}(t) \\right) dt,\n",
    "$$\n",
    "where the expression in parentheses is zero for all $t$, giving a freedom in choosing $\\lambda(t)$.\n",
    "After applying integration by parts and rearrangement of the terms, the gradient of the objective becomes:\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\frac{d\\mathcal{L}}{d\\mathbf{p}} = \\frac{dJ}{d\\mathbf{p}} =& \\int_{t_0}^{T} \\left[\n",
    "        \\frac{\\delta h}{\\delta \\mathbf{p}}\n",
    "        + \\lambda(t)^{\\top} \\frac{\\delta \\mathbf{f}}{\\delta \\mathbf{p}}\n",
    "        + \\left( \\frac{\\delta h}{\\delta \\mathbf{u}}\n",
    "            + \\lambda(t)^{\\top} \\frac{\\delta \\mathbf{f}}{\\delta \\mathbf{u}}\n",
    "            + \\frac{d \\lambda(t)^{\\top}}{dt}\n",
    "        \\right) \\frac{\\delta \\mathbf{u}}{\\delta \\mathbf{p}}\n",
    "    \\right] dt \\nonumber \\\\\n",
    "    &+ \\lambda(t_0)^{\\top} \\frac{\\delta \\mathbf{u}}{\\delta \\mathbf{p}}(t_0)\n",
    "    - \\lambda(T)^{\\top} \\frac{\\delta \\mathbf{u}}{\\delta \\mathbf{p}}(T).     \\tag{8}\n",
    "\\end{align}\n",
    "$$\n",
    "Since we are free to choose $\\lambda(t)$, we can form the following adjoint ODE (as a terminal-value problem),\n",
    "$$\n",
    "    \\frac{d \\lambda(t)}{dt} =                                               \\tag{9}\n",
    "        - \\frac{\\delta \\mathbf{f}}{\\delta \\mathbf{u}}^{\\top} \\lambda(t)\n",
    "        - \\frac{\\delta h}{\\delta \\mathbf{u}}^{\\top},\n",
    "    \\;\\; \\lambda(T) = 0,\n",
    "$$\n",
    "so that we can eliminate the difficult-to-calculate $\\frac{\\delta u}{\\delta \\mathbf{p}}$ term.\n",
    "Then, the sensitivity $\\frac{d\\mathcal{L}}{dp}$ to be used in gradient descent can be calculated efficiently as follows.\n",
    "\n",
    "- Numerically solve the original ODE (initial-value problem) given by Eq. (4) forward to estimate the solution $\\hat{\\mathbf{u}}(t)$.\n",
    "- Numerically solve the adjoint terminal-value problem given by Eq. (9) backward to estimate the solution $\\lambda(t)$.\n",
    "- Numerically evaluate the integral in Eq. (10) forward (by setting $w(0) = 0$) or backward (by setting $w(T) = 0$). The result of the evaluation is the value of the $\\frac{d\\mathcal{L}}{d\\mathbf{p}}$ or its negative based on the integration direction.\n",
    "\n",
    "$$\n",
    "    \\frac{dJ}{d\\mathbf{p}} = \\int_{t_0}^{T} \\left[                          \\tag{10}\n",
    "        \\frac{\\delta h}{\\delta \\mathbf{p}}\n",
    "         + \\lambda(t)^{\\top} \\frac{\\delta \\mathbf{f}}{\\delta \\mathbf{p}}\n",
    "    \\right] dt + \\lambda(t_0)^{\\top} \\frac{\\delta \\mathbf{u}}{\\delta \\mathbf{p}}(t_0).\n",
    "$$\n",
    "\n",
    "Then, the update rule of the gradient descent algorithm is\n",
    "$$\n",
    "    \\mathbf{p} \\leftarrow \\mathbf{p} - \\eta \\frac{dJ}{d\\mathbf{p}}.         \\tag{11}\n",
    "$$\n",
    "\n",
    "In the subsequent sections, we attempt to solve the problem by comparing the performances of different tools."
   ],
   "id": "1c725194dcbc995f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:43:07.945911Z",
     "start_time": "2025-03-19T20:43:07.941830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Common gradient descent settings:\n",
    "num_epochs = 2000\n",
    "eta = 2     # Learning rate of the gradient descent.\n",
    "g0 = -9.81  # Initial guess for the gravity: assume Earth.\n",
    "v0 = 0      # Initial guess for the velocity: assume zero."
   ],
   "id": "5c693b21c39c81fe",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analytical Differentiation of the Terms\n",
    "\n",
    "The procedure described in previous section requires calculation of several partial derivatives. In this section, we use the analytical differentiation.\n",
    "$$\n",
    "    \\frac{\\delta \\mathbf{f}}{\\delta \\mathbf{u}} =\n",
    "        \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}, \\;\\;\\;\\;\\;\n",
    "    \\frac{\\delta h}{\\delta \\mathbf{u}} =\n",
    "        \\begin{bmatrix} u_1(t) - u_1^*(t) & 0 \\end{bmatrix}                         \\tag{12}\n",
    "$$$$\n",
    "    \\frac{\\delta \\mathbf{f}}{\\delta \\mathbf{p}} =\n",
    "        \\begin{bmatrix} 0 & 0 \\\\ 1 & 0 \\end{bmatrix}, \\;\\;\\;\\;\\;\n",
    "    \\frac{\\delta h}{\\delta \\mathbf{p}} =\n",
    "        \\begin{bmatrix} 0 & 0 \\end{bmatrix}, \\;\\;\\;\\;\\;\n",
    "    \\frac{\\delta \\mathbf{u}}{\\delta \\mathbf{p}}(t_0) =\n",
    "        \\begin{bmatrix} 0 & 0 \\\\ 0 & 1 \\end{bmatrix}                                \\tag{13}\n",
    "$$\n",
    "Plugging Eq. (12) into (9) and Eq. (13) into (10), we can follow the procedure to find the parameters as follows."
   ],
   "id": "c2915bdab314c177"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:43:19.877336Z",
     "start_time": "2025-03-19T20:43:07.968923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from odes import falling_ball_adjoint\n",
    "\n",
    "pred_gv, u_sols, costs = falling_ball_adjoint.optimize(\n",
    "    v0, g0, ut, t_eval, eta, num_epochs\n",
    ")\n",
    "print(f\"Grav. acc.: Predicted ({pred_gv[-1, 0]:.5f})\"\n",
    "      f\" ~= ({g_best:.5f}) LS estimation\")\n",
    "print(f\"Init. vel.: Predicted ( {pred_gv[-1, 1]:.5f})\"\n",
    "      f\" ~= ( {v0_best:.5f}) LS estimation\")"
   ],
   "id": "9c80aeed7c8469a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grav. acc.: Predicted (-3.70011) ~= (-3.70002) LS estimation\n",
      "Init. vel.: Predicted ( 0.10189) ~= ( 0.10185) LS estimation\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
